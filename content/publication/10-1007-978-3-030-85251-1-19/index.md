---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Overview of the CLEF--2021 CheckThat! Lab on Detecting Check-Worthy Claims,
  Previously Fact-Checked Claims, and Fake News
subtitle: ''
summary: ''
authors:
- Preslav Nakov
- Giovanni Da San Martino
- Tamer Elsayed
- Alberto Barrón-Cedeño
- Rubén Míguez
- Shaden Shaar
- Firoj Alam
- Fatima Haouari
- Maram Hasanain
- Watheq Mansour
- Bayan Hamdan
- Zien Sheikh Ali
- Nikolay Babulkov
- Alex Nikolov
- Gautam Kishore Shahi
- Julia Maria Struß
- Thomas Mandl
- Mucahid Kutlu
- Yavuz Selim Kartal
tags: []
categories: []
date: '2021-01-01'
lastmod: 2022-01-27T17:34:59+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-01-27T16:34:59.845323Z'
publication_types:
- '1'
abstract: 'We describe the fourth edition of the CheckThat! Lab, part of the 2021
  Conference and Labs of the Evaluation Forum (CLEF). The lab evaluates technology
  supporting tasks related to factuality, and covers Arabic, Bulgarian, English, Spanish,
  and Turkish. Task 1 asks to predict which posts in a Twitter stream are worth fact-checking,
  focusing on COVID-19 and politics (in all five languages). Task 2 asks to determine
  whether a claim in a tweet can be verified using a set of previously fact-checked
  claims (in Arabic and English). Task 3 asks to predict the veracity of a news article
  and its topical domain (in English). The evaluation is based on mean average precision
  or precision at rank k for the ranking tasks, and macro-F11for the classification
  tasks. This was the most popular CLEF-2021 lab in terms of team registrations: 132
  teams. Nearly one-third of them participated: 15, 5, and 25 teams submitted official
  runs for tasks 1, 2, and 3, respectively.'
publication: '*Experimental IR Meets Multilinguality, Multimodality, and Interaction*'
---
