---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: 'Harmful Language Datasets: An Assessment of Robustness'
subtitle: ''
summary: ''
authors:
- Katerina Korre
- John Pavlopoulos
- Jeffrey Sorensen
- Léo Laugier
- Ion Androutsopoulos
- Lucas Dixon
- Alberto Barrón-cedeño
tags: []
categories: []
date: '2023-07-01'
lastmod: 2023-10-27T12:47:54+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-10-27T10:47:54.504083Z'
publication_types:
- '1'
abstract: The automated detection of harmful language has been of great importance
  for the online world, especially with the growing importance of social media and,
  consequently, polarisation. There are many open challenges to high quality detection
  of harmful text, from dataset creation to generalisable application, thus calling
  for more systematic studies. In this paper, we explore re-annotation as a means
  of examining the robustness of already existing labelled datasets, showing that,
  despite using alternative definitions, the inter-annotator agreement remains very
  inconsistent, highlighting the intrinsically subjective and variable nature of the
  task. In addition, we build automatic toxicity detectors using the existing datasets,
  with their original labels, and we evaluate them on our multi-definition and multi-source
  datasets. Surprisingly, while other studies show that hate speech detection models
  perform better on data that are derived from the same distribution as the training
  set, our analysis demonstrates this is not necessarily true.
publication: '*The 7th Workshop on Online Abuse and Harms (WOAH)*'
doi: 10.18653/v1/2023.woah-1.24
links:
- name: URL
  url: https://aclanthology.org/2023.woah-1.24
---
