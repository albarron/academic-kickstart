{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWGcrooIk4-e"
      },
      "source": [
        "# Neural networks\n",
        "\n",
        "We are using Keras. Don't forget to install it (e.g., `pip install keras`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u0XOW5Xk4-f"
      },
      "outputs": [],
      "source": [
        "# Do not forget to install keras the first time\n",
        "# (this is already installed on colab)\n",
        "! pip3 install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEAXOMKMk4-g"
      },
      "outputs": [],
      "source": [
        "# Importing all the dependencies necessary for this notebook (except for keras)\n",
        "import matplotlib.pyplot as plt\n",
        "from math import e\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTLCdNTpk4-i"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "x = np.arange(-10.0, 10.0, 0.01)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9miOd0fk4-i"
      },
      "outputs": [],
      "source": [
        "y = 1 / (1 + e**(-x))\n",
        "plt.plot(x, y)\n",
        "plt.axhline(y=0.5, xmin=-10, xmax=10, linestyle=\":\", linewidth=0.5)\n",
        "plt.axvline(x=0, ymin=-10, ymax=10, linestyle=\":\", linewidth=0.5)\n",
        "fig.savefig(\"10_sigmoid.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7e4a-iek4-i"
      },
      "outputs": [],
      "source": [
        "#Curious abput what is in x and y?\n",
        "print(\"x\\ty\")\n",
        "for i, j in zip(x, y): #range(len(x)):\n",
        "    print(i.round(2), \"\\t\", j.round(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqacEDK-k4-k"
      },
      "source": [
        "**Back to the slides**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCkNqm-yk4-k"
      },
      "source": [
        "## Neural network to lean the XOR logical function\n",
        "\n",
        "With non-linear functions and more than one neuron, we can learn more sophisticated functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Z8Mx4wk4-l"
      },
      "outputs": [],
      "source": [
        "# Instances for XOR\n",
        "x_train = np.array(\n",
        "    [[0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]])\n",
        "y_train = np.array(\n",
        "    [[0],\n",
        "    [1],\n",
        "    [1],\n",
        "    [0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTm09LGxk4-m"
      },
      "outputs": [],
      "source": [
        "# Base Keras model class (even if this model is not sequential)\n",
        "from keras.models import Sequential\n",
        "\n",
        "# We will use a fully-connected layer of units\n",
        "from keras.layers import Dense\n",
        "\n",
        "# In order to get access to many activation functions\n",
        "from keras.layers import Activation\n",
        "\n",
        "# We use stochastic gradient descent\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XeFXx_tk4-m"
      },
      "outputs": [],
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "num_neurons = 10\n",
        "\n",
        "# Hidden layer with tanh activation functions\n",
        "# How many units does it have?\n",
        "model.add(Dense(num_neurons, input_dim=2))\n",
        "model.add(Activation('tanh'))\n",
        "\n",
        "# (let us scroll down to find out what is tanh: Hyperbolic tangent of x)\n",
        "\n",
        "# Output layer with one neuron and sigmoid activation function\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "# Let's go to the slides (after analysing this summary a bit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tok-dMJBk4-n"
      },
      "source": [
        "First of all, [what is e](https://en.wikipedia.org/wiki/E_(mathematical_constant))?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZileYCifk4-n"
      },
      "outputs": [],
      "source": [
        "# The tanh (hyperbolic tangent)\n",
        "\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "x = np.arange(-10.0, 10.0, 0.01)\n",
        "y = (e**x - e**(-x))/(e**x + e**(-x))\n",
        "plt.plot(x, y)\n",
        "plt.axhline(y=0, xmin=-10, xmax=10, linestyle=\":\", linewidth=0.5)\n",
        "plt.axvline(x=0, ymin=-10, ymax=10, linestyle=\":\", linewidth=0.5)\n",
        "fig.savefig(\"10_tanh.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_58BRGPsk4-n"
      },
      "outputs": [],
      "source": [
        "# Building the model with stochastic gradient descent and alpha=0.1\n",
        "# (alpha is the learning rate)\n",
        "sgd = SGD(learning_rate=0.1)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZsO-zDWk4-n"
      },
      "outputs": [],
      "source": [
        "# Predicting with this model (before training)\n",
        "model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVWWG5--k4-o"
      },
      "outputs": [],
      "source": [
        "# Train (fit) the model (if it doesn't converge, add more epochs)\n",
        "# (notice that this can be launched many times, augmenting the number of epochs)\n",
        "model.fit(x_train, y_train, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVYhpyWZk4-o"
      },
      "outputs": [],
      "source": [
        "# Predicting with this model (after training)\n",
        "# model.predict_classes(x_train)\n",
        "model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78wupE8vk4-o"
      },
      "outputs": [],
      "source": [
        "# Using round to get classes\n",
        "model.predict(x_train).round()\n",
        "\n",
        "# Why this round works here:\n",
        "# The threshold is at 0.5\n",
        "# This is a binary problem (the story is a bid different for multi-class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avx3QNgGk4-o"
      },
      "source": [
        "Finally, you can save your model to, for instance, deploy it later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irdvonE2k4-p"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "model_structure = model.to_json()\n",
        "with open(\"basic_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_structure)\n",
        "model.save_weights(\"basic_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4oXJrrnk4-p"
      },
      "source": [
        "# Homework\n",
        "\n",
        "**Play with the XOR**\n",
        "    \n",
        "1. Add more units in the hidden layer\n",
        "2. Use different activation functions\n",
        "3. Change the learning rate\n",
        "4. Change the number of epochs\n",
        "5. Implement (and test) an OR and an XOR with 3 inputs:\n",
        "\n",
        "| input | OR | XOR |\n",
        "|:-----:|:--:|:--:|\n",
        "| 0 0 0 | 0  | 0  |\n",
        "| 0 0 1 | 1  | 1  |\n",
        "| 0 1 0 | 1  | 1  |\n",
        "| 0 1 1 | 1  | 0  |\n",
        "| 1 0 0 | 1  | 1  |\n",
        "| 1 0 1 | 1  | 0  |\n",
        "| 1 1 0 | 1  | 0  |\n",
        "| 1 1 1 | 1  | 1  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvdfJt1Tk4-p"
      },
      "source": [
        "end of the notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}