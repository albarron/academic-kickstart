{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93iGB2PMDiaa"
   },
   "source": [
    "# Introducing the Naive Bayes Classifier\n",
    "\n",
    "Now we will use annotated data to \"learn\" a sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-sX590NpDiab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.14\r\n"
     ]
    }
   ],
   "source": [
    "# We first install the new dependency: nlpia (03_dit_coli_naivebayes.ipynb)\n",
    "# ! pip3 install nlpia\n",
    "\n",
    "! python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t8ZXWCunDiad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
      "/usr/local/lib/python3.8/site-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
      "/usr/local/lib/python3.8/site-packages/pugnlp/tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "/usr/local/lib/python3.8/site-packages/pugnlp/util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "/usr/local/lib/python3.8/site-packages/nlpia/futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "/usr/local/lib/python3.8/site-packages/nlpia/loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n"
     ]
    }
   ],
   "source": [
    "# Loading the dependencies\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nlpia.data.loaders import get_data \n",
    "\n",
    "# The casual tokenizer can handle emoticons, unusual punctuation and slang better than the TreeBank tokenizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEEXu6s3Diae"
   },
   "source": [
    "## Setting up the _corpus_\n",
    "\n",
    "Loading the movies corpus from Hutto movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1MksGSDODiaf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.27</td>\n",
       "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.53</td>\n",
       "      <td>The gorgeously elaborate continuation of ''The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.60</td>\n",
       "      <td>Effective but too tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.47</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.73</td>\n",
       "      <td>Emerges as something rare, an issue movie that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                               text\n",
       "id                                                              \n",
       "1        2.27  The Rock is destined to be the 21st Century's ...\n",
       "2        3.53  The gorgeously elaborate continuation of ''The...\n",
       "3       -0.60                     Effective but too tepid biopic\n",
       "4        1.47  If you sometimes like to go to the movies to h...\n",
       "5        1.73  Emerges as something rare, an issue movie that..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = get_data('hutto_movies')\n",
    "\n",
    "# Looking at some of the first instances\n",
    "movies.head().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvTU4XVmDiag"
   },
   "source": [
    "### Getting a description of the data (look at the range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GxQnvm9lDiah"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10605.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "count   10605.00\n",
       "mean        0.00\n",
       "std         1.92\n",
       "min        -3.88\n",
       "25%        -1.77\n",
       "50%        -0.08\n",
       "75%         1.83\n",
       "max         3.94"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xCo9AMhLDiah"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1        2.266667\n",
       "2        3.533333\n",
       "3       -0.600000\n",
       "4        1.466667\n",
       "5        1.733333\n",
       "           ...   \n",
       "10601   -0.062500\n",
       "10602   -1.500000\n",
       "10603   -0.625000\n",
       "10604    1.437500\n",
       "10605   -1.812500\n",
       "Name: sentiment, Length: 10605, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helps display wide DataFrames in the console, so they look prettier\n",
    "pd.set_option('display.width', 75)\n",
    "movies.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1BsQK-4Diai"
   },
   "source": [
    "### Loading the data into a BoW DataFrame through a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GpeFR1i6Diaj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       The  Rock   is  destined   to   be  the  21st  Century's  new  \\\n",
      "0      1.0   1.0  1.0       1.0  2.0  1.0  1.0   1.0        1.0  1.0   \n",
      "1      2.0   NaN  1.0       NaN  NaN  NaN  1.0   NaN        NaN  NaN   \n",
      "2      NaN   NaN  NaN       NaN  NaN  NaN  NaN   NaN        NaN  NaN   \n",
      "3      NaN   NaN  1.0       NaN  4.0  NaN  1.0   NaN        NaN  NaN   \n",
      "4      NaN   NaN  NaN       NaN  NaN  NaN  NaN   NaN        NaN  NaN   \n",
      "...    ...   ...  ...       ...  ...  ...  ...   ...        ...  ...   \n",
      "10600  NaN   NaN  NaN       NaN  NaN  NaN  NaN   NaN        NaN  NaN   \n",
      "10601  NaN   NaN  NaN       NaN  NaN  NaN  NaN   NaN        NaN  NaN   \n",
      "10602  NaN   NaN  NaN       NaN  NaN  NaN  NaN   NaN        NaN  NaN   \n",
      "10603  NaN   NaN  NaN       NaN  NaN  NaN  2.0   NaN        NaN  NaN   \n",
      "10604  NaN   NaN  NaN       NaN  NaN  NaN  2.0   NaN        NaN  NaN   \n",
      "\n",
      "       ...  Ill  slummer  Rashomon  dipsticks  Bearable  Staggeringly  \\\n",
      "0      ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "1      ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "2      ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "3      ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "4      ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "...    ...  ...      ...       ...        ...       ...           ...   \n",
      "10600  ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "10601  ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "10602  ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "10603  ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "10604  ...  NaN      NaN       NaN        NaN       NaN           NaN   \n",
      "\n",
      "         ’   ve  muttering  dissing  \n",
      "0      NaN  NaN        NaN      NaN  \n",
      "1      NaN  NaN        NaN      NaN  \n",
      "2      NaN  NaN        NaN      NaN  \n",
      "3      NaN  NaN        NaN      NaN  \n",
      "4      NaN  NaN        NaN      NaN  \n",
      "...    ...  ...        ...      ...  \n",
      "10600  NaN  NaN        NaN      NaN  \n",
      "10601  NaN  NaN        NaN      NaN  \n",
      "10602  NaN  NaN        NaN      NaN  \n",
      "10603  2.0  1.0        NaN      NaN  \n",
      "10604  NaN  NaN        1.0      1.0  \n",
      "\n",
      "[10605 rows x 20756 columns]\n"
     ]
    }
   ],
   "source": [
    "bags_of_words = []\n",
    "\n",
    "for text in movies.text:\n",
    "    bags_of_words.append(Counter(casual_tokenize(text)))\n",
    "\n",
    "df_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "\n",
    "# from_records() is a DataFrame constructor.\n",
    "# INPUT: a sequence (list) of dictionaries\n",
    "# OUTPUT: a DF with columns for all the keys and associated values. \n",
    "# (Missing values become NaN!)\n",
    "print(df_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cU1Hv7K1Diak"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
      "0        1     1   1         1   2   1    1     1          1    1  ...   \n",
      "1        2     0   1         0   0   0    1     0          0    0  ...   \n",
      "2        0     0   0         0   0   0    0     0          0    0  ...   \n",
      "3        0     0   1         0   4   0    1     0          0    0  ...   \n",
      "4        0     0   0         0   0   0    0     0          0    0  ...   \n",
      "...    ...   ...  ..       ...  ..  ..  ...   ...        ...  ...  ...   \n",
      "10600    0     0   0         0   0   0    0     0          0    0  ...   \n",
      "10601    0     0   0         0   0   0    0     0          0    0  ...   \n",
      "10602    0     0   0         0   0   0    0     0          0    0  ...   \n",
      "10603    0     0   0         0   0   0    2     0          0    0  ...   \n",
      "10604    0     0   0         0   0   0    2     0          0    0  ...   \n",
      "\n",
      "       Ill  slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
      "0        0        0         0          0         0             0  0   0   \n",
      "1        0        0         0          0         0             0  0   0   \n",
      "2        0        0         0          0         0             0  0   0   \n",
      "3        0        0         0          0         0             0  0   0   \n",
      "4        0        0         0          0         0             0  0   0   \n",
      "...    ...      ...       ...        ...       ...           ... ..  ..   \n",
      "10600    0        0         0          0         0             0  0   0   \n",
      "10601    0        0         0          0         0             0  0   0   \n",
      "10602    0        0         0          0         0             0  0   0   \n",
      "10603    0        0         0          0         0             0  2   1   \n",
      "10604    0        0         0          0         0             0  0   0   \n",
      "\n",
      "       muttering  dissing  \n",
      "0              0        0  \n",
      "1              0        0  \n",
      "2              0        0  \n",
      "3              0        0  \n",
      "4              0        0  \n",
      "...          ...      ...  \n",
      "10600          0        0  \n",
      "10601          0        0  \n",
      "10602          0        0  \n",
      "10603          0        0  \n",
      "10604          1        1  \n",
      "\n",
      "[10605 rows x 20756 columns]\n"
     ]
    }
   ],
   "source": [
    "# So we fill them with 0:\n",
    "df_bows = df_bows.fillna(0).astype(int)\n",
    "print(df_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uX3jwWktDian"
   },
   "source": [
    "### Let us look at the shape\n",
    "\n",
    "**Spoiler**: A BoW can explode in size; even more when no normalisation is applied at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xKu4rVYyDian"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10605, 20756)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O54rsOArDiao"
   },
   "source": [
    "Now, let us see the first instances (it is quite sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nu9n3UHGDiao"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Rock</th>\n",
       "      <th>is</th>\n",
       "      <th>destined</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>the</th>\n",
       "      <th>21st</th>\n",
       "      <th>Century's</th>\n",
       "      <th>new</th>\n",
       "      <th>...</th>\n",
       "      <th>Ill</th>\n",
       "      <th>slummer</th>\n",
       "      <th>Rashomon</th>\n",
       "      <th>dipsticks</th>\n",
       "      <th>Bearable</th>\n",
       "      <th>Staggeringly</th>\n",
       "      <th>’</th>\n",
       "      <th>ve</th>\n",
       "      <th>muttering</th>\n",
       "      <th>dissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  Ill  \\\n",
       "0    1     1   1         1   2   1    1     1          1    1  ...    0   \n",
       "1    2     0   1         0   0   0    1     0          0    0  ...    0   \n",
       "2    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
       "3    0     0   1         0   4   0    1     0          0    0  ...    0   \n",
       "4    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
       "\n",
       "   slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
       "0        0         0          0         0             0  0   0   \n",
       "1        0         0          0         0             0  0   0   \n",
       "2        0         0          0         0             0  0   0   \n",
       "3        0         0          0         0             0  0   0   \n",
       "4        0         0          0         0             0  0   0   \n",
       "\n",
       "   muttering  dissing  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "\n",
       "[5 rows x 20756 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Awaj-M-oDiap"
   },
   "source": [
    "\n",
    "**Homework**: Integrate the normalisation pipeline (lowercasing, stopwording and stemming or lemmatisation) and see how the dataframe gets affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUBDqzFLDiap"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6VMVsj9dDiaq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
      "0    1     1   1         1   2   1    1     1          1    1  ...   \n",
      "1    2     0   1         0   0   0    1     0          0    0  ...   \n",
      "2    0     0   0         0   0   0    0     0          0    0  ...   \n",
      "3    0     0   1         0   4   0    1     0          0    0  ...   \n",
      "4    0     0   0         0   0   0    0     0          0    0  ...   \n",
      "\n",
      "   Schwarzenegger  ,  Jean  Claud  Van  Damme  or  Steven  Segal  .  \n",
      "0               1  1     1      1    1      1   1       1      1  1  \n",
      "1               0  0     0      0    0      0   0       0      0  4  \n",
      "2               0  0     0      0    0      0   0       0      0  0  \n",
      "3               0  1     0      0    0      0   0       0      0  1  \n",
      "4               0  1     0      0    0      0   0       0      0  1  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "   The  gorgeously  elaborate  continuation  of  '  Lord  the  Rings  \\\n",
      "0    1           0          0             0   0  4     0    1      0   \n",
      "1    2           1          1             1   4  4     1    1      1   \n",
      "2    0           0          0             0   0  0     0    0      0   \n",
      "3    0           0          0             0   0  0     0    1      0   \n",
      "4    0           0          0             0   0  0     0    0      0   \n",
      "\n",
      "   trilogy  ...  Peter  Jackson's  expanded  vision  J  .  R  Tolkien's  \\\n",
      "0        0  ...      0          0         0       0  0  1  0          0   \n",
      "1        1  ...      1          1         1       1  1  4  2          1   \n",
      "2        0  ...      0          0         0       0  0  0  0          0   \n",
      "3        0  ...      0          0         0       0  0  1  0          0   \n",
      "4        0  ...      0          0         0       0  0  1  0          0   \n",
      "\n",
      "   Middle  earth  \n",
      "0       0      0  \n",
      "1       1      1  \n",
      "2       0      0  \n",
      "3       0      0  \n",
      "4       0      0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_bows.head()[list(bags_of_words[0].keys())])\n",
    "print(df_bows.head()[list(bags_of_words[1].keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ATeewTDDiaq"
   },
   "source": [
    "### Build the Nave Bayes' classifier\n",
    "\n",
    "All the data is now ready. Let us build a Multinomial NB.\n",
    "\n",
    "Multinomial NB is suitable for discrete features (e.g., word counts for text classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z27VwyjsDiaq"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhWrv5S3Diar"
   },
   "outputs": [],
   "source": [
    "# \"Binarising\" the classes\n",
    "movies.sentiment > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwQ_hZEmDiar"
   },
   "source": [
    "Now we can train (\"fit\") our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkaG5fTdDiar"
   },
   "outputs": [],
   "source": [
    "# We are converting the class from float to Boolean, \n",
    "# as this classifier only supports discrete labels \n",
    "nb = nb.fit(df_bows, movies.sentiment > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtOrrSqADiar"
   },
   "source": [
    "### We have a model and we can predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmdvwdQoDias"
   },
   "outputs": [],
   "source": [
    "# predict_proba() gets continious-value predictions.\n",
    "# We multiply and subtract it to convert the output to range [-4,4]\n",
    "\n",
    "#print(predictions[:10])\n",
    "# TODO there seems to be an error in th ebook code. \n",
    "# predict_proba returns the scores for all the classes (2) and we aim at\n",
    "# assigning only the one for the positive class. \n",
    "# I had to to the following trick instead of the original\n",
    "# movies['predicted_sentiment'] = nb.predict(df_bows) * 8 - 4\n",
    "predictions = nb.predict_proba(df_bows) * 8 - 4 \n",
    "movies['predicted_sentiment'] = [x[1] for x in predictions]\n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js3TVM6sDiat"
   },
   "source": [
    "Now, we compute the [Mean Absolut Error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) \"a measure of difference between two continuous variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZEBytu4Diat",
    "outputId": "a049fecc-171a-407e-c62f-98061f93fd35"
   },
   "outputs": [],
   "source": [
    "movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs()\n",
    "# This is the mean absolute error (MAE)\n",
    "round(movies.error.mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYADj2RAEz0L"
   },
   "outputs": [],
   "source": [
    "# abs(n)\n",
    "\n",
    "# abs(5) -> 5\n",
    "# abs(-34) -> 34\n",
    "# abs(0) -> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrXXp1ozDiau"
   },
   "source": [
    "Now, let us see some gold and predicted sentiments, together with the binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PALMjqNSDiau"
   },
   "outputs": [],
   "source": [
    "# Gold standard is positive\n",
    "movies['sentiment_ispositive'] = (movies.sentiment > 0).astype(int)\n",
    "\n",
    "# Prediction is positive\n",
    "movies['predicted_ispositive'] = (movies.predicted_sentiment > 0).astype(int)\n",
    "\n",
    "# Let us have an overview of gold standard vs prediction\n",
    "movies['''sentiment predicted_sentiment sentiment_ispositive predicted_ispositive'''.split()].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr05Vwv6Diau"
   },
   "outputs": [],
   "source": [
    "# And this is the percentage of \"thumbs up\" rating correctly predicted    \n",
    "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW9yBVYqDiav"
   },
   "source": [
    "## not bad at all!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_dit_coli_naivebayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
