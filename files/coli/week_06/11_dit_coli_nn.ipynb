{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A gentle introduction to neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input, weighs and bias\n",
    "example_input   = [1, .2, .1, .05, .2]\n",
    "example_weights = [.2, .12, .4, .6, .90]\n",
    "\n",
    "input_vector = np.array(example_input)\n",
    "weights = np.array(example_weights)\n",
    "bias_weight = .25\n",
    "\n",
    "# Just a dot product (+ the bias)\n",
    "activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
    "activation_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "threshold = 0.5\n",
    "if activation_level >= threshold:\n",
    "    perceptron_output = 1\n",
    "else:\n",
    "    perceptron_output = 0\n",
    "# There is an error in this line of the book\n",
    "perceptron_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to the slides**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_output = 0\n",
    "new_weights = []\n",
    "for i, x in enumerate(example_input):\n",
    "    new_weights.append(weights[i] + (expected_output -perceptron_output) * x)\n",
    "weights = np.array(new_weights)\n",
    "print(\"Original weights:\", example_weights)\n",
    "print(\"New weights:\\t\", weights)\n",
    "\n",
    "# Back to the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kind of functions that $y=w^T x$ can learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-4, 5, 2):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.spines['left'].set_position('center')\n",
    "    ax.spines['bottom'].set_position('center')\n",
    "    # Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "\n",
    "    ax.set(title='$y=w^Tx$')\n",
    "    x = np.arange(-10.0, 10.0, 0.01)\n",
    "\n",
    "    plt.xlim((-11,+11))\n",
    "    plt.ylim((-11,+11))\n",
    "    ax.set(title='$y={}x$'.format(i))\n",
    "    y = i*x\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    fig.savefig(\"linear_w{}.png\".format(i))\n",
    "    plt.show()\n",
    "    # plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kind of functions that $y=w^T x +b$ can learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-4, 5, 2):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.spines['left'].set_position('center')\n",
    "    ax.spines['bottom'].set_position('center')\n",
    "    # Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "\n",
    "    ax.set(title='$y=w^Tx$')\n",
    "    x = np.arange(-10.0, 10.0, 0.01)\n",
    "\n",
    "    plt.xlim((-11,+11))\n",
    "    plt.ylim((-11,+11))\n",
    "    ax.set(title='$y=x + {}$'.format(i))\n",
    "    y = x + i\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    fig.savefig(\"linear_b{}.png\".format(i))\n",
    "    plt.show()\n",
    "    # plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning an OR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: input and expected output\n",
    "sample_data = [\n",
    "        [0, 0], # False, False\n",
    "        [0, 1],    # False, True\n",
    "        [1, 0],    # True, False\n",
    "        [1, 1]     # True, True\n",
    "        ] \n",
    "expected_results = [0, # (False OR False) gives False\n",
    "                    1, # (False OR True ) gives True\n",
    "                    1, # (True OR False) gives True\n",
    "                    1] # (True OR True ) gives True\n",
    "activation_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the weights with a small random float 0 < w < .001\n",
    "weights = np.random.random(2)/1000\n",
    "bias_weight = np.random.random() / 1000\n",
    "\n",
    "print(\"weights:\\t\", weights)\n",
    "print(\"bias weight:\\t\", bias_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random guessing\n",
    "for idx, sample in enumerate(sample_data):\n",
    "    input_vector = np.array(sample)\n",
    "    activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
    "    if activation_level > activation_threshold:\n",
    "        perceptron_output = 1\n",
    "    else:\n",
    "        perceptron_output = 0\n",
    "    print('Predicted {}'.format(perceptron_output))\n",
    "    print('Expected: {}\\n'.format(expected_results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the weights\n",
    "\n",
    "We are doing this with a for loop, which is not efficient at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iteration_num in range(5):\n",
    "    correct_answers = 0\n",
    "    for idx, sample in enumerate(sample_data):\n",
    "        input_vector = np.array(sample)\n",
    "        weights = np.array(weights)\n",
    "        activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
    "        \n",
    "        if activation_level > activation_threshold:\n",
    "            perceptron_output = 1\n",
    "        else:\n",
    "            perceptron_output = 0\n",
    "        \n",
    "        if perceptron_output == expected_results[idx]:\n",
    "            correct_answers += 1\n",
    "        \n",
    "        # updating all weights\n",
    "        new_weights = []\n",
    "        for i, x in enumerate(sample):\n",
    "            new_weights.append(weights[i] + (expected_results[idx] - perceptron_output) * x)\n",
    "            \n",
    "        bias_weight = bias_weight + ((expected_results[idx] - perceptron_output) * 1)\n",
    "        weights = np.array(new_weights)\n",
    "        \n",
    "    print('iteration {}: {} correct answers out of 4'.format(iteration_num, correct_answers))\n",
    "# Back to the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to the slides**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Learning_ an XOR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: input and expected output\n",
    "sample_data = [\n",
    "    [0, 0], \n",
    "    [0, 1],    \n",
    "    [1, 0],    \n",
    "    [1, 1]     \n",
    "  ] \n",
    "expected_results = [0, \n",
    "                    1, \n",
    "                    1, \n",
    "                    0] # The one and only change!\n",
    "activation_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the weights with a small random float 0 < w < .001\n",
    "weights = np.random.random(2)/1000\n",
    "bias_weight = np.random.random() / 1000\n",
    "\n",
    "print(\"weights:\\t\", weights)\n",
    "print(\"bias weight:\\t\", bias_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration_num in range(10):\n",
    "    correct_answers = 0\n",
    "    for idx, sample in enumerate(sample_data):\n",
    "        input_vector = np.array(sample)\n",
    "        weights = np.array(weights)\n",
    "        activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
    "        \n",
    "        if activation_level > activation_threshold:\n",
    "            perceptron_output = 1\n",
    "        else:\n",
    "            perceptron_output = 0\n",
    "        \n",
    "        if perceptron_output == expected_results[idx]:\n",
    "            correct_answers += 1\n",
    "        \n",
    "        # updating all weights\n",
    "        new_weights = []\n",
    "        for i, x in enumerate(sample):\n",
    "            new_weights.append(weights[i] + (expected_results[idx] - perceptron_output) * x)\n",
    "            \n",
    "        bias_weight = bias_weight + ((expected_results[idx] - perceptron_output) * 1)\n",
    "        weights = np.array(new_weights)\n",
    "        \n",
    "    print('iteration {}: {} correct answers out of 4'.format(iteration_num, correct_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the slides"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
