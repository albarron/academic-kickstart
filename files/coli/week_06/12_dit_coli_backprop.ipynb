{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "We are using Keras. Don't forget to install it (e.g., `pip install keras`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the dependencies necessary for this notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from math import e\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "x = np.arange(-10.0, 10.0, 0.01)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1 / (1 + e**(-x))\n",
    "plt.plot(x, y)\n",
    "plt.axhline(y=0.5, xmin=-10, xmax=10, linestyle=\":\", linewidth=0.5)\n",
    "plt.axvline(x=0, ymin=-10, ymax=10, linestyle=\":\", linewidth=0.5)\n",
    "fig.savefig(\"10_sigmoid.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curious abput what is in x and y?\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network for XOR\n",
    "\n",
    "With non-linear functions and more than one neuron, we can learn more sophisticated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Keras model class\n",
    "from keras.models import Sequential\n",
    "# We want a fully-connected layer of neurons\n",
    "from keras.layers import Dense \n",
    "# Now we have access to activation functions :)\n",
    "from keras.layers import Activation\n",
    "# We use stochastic gradient descent\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will see this in a second. Let's scroll down\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "x = np.arange(-10.0, 10.0, 0.01)\n",
    "y = (e**x - e**(-x))/(e**x + e**(-x))\n",
    "plt.plot(x, y)\n",
    "plt.axhline(y=0, xmin=-10, xmax=10, linestyle=\":\", linewidth=0.5)\n",
    "plt.axvline(x=0, ymin=-10, ymax=10, linestyle=\":\", linewidth=0.5)\n",
    "fig.savefig(\"10_tanh.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instances for XOR\n",
    "x_train = np.array(\n",
    "    [[0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]])\n",
    "y_train = np.array(\n",
    "    [[0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]])\n",
    "\n",
    "# Defining the model\n",
    "model = Sequential()\n",
    "num_neurons = 10\n",
    "\n",
    "# Hidden layer followed with tanh activation function\n",
    "model.add(Dense(num_neurons, input_dim=2))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "# Output layer with one neuron and sigmoid activation function \n",
    "# (let's scroll up and see what is tanh: Hyperbolic tangent of x)\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "# Let's go to the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model with stochastic gradient descent and alpha=0.1\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with this model (before training)\n",
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (fit) the model (if it doesn't converge, add more epochs)\n",
    "model.fit(x_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with this model (after training)\n",
    "model.predict_classes(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can save your model to, for instance, deploy it later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model_structure = model.to_json()\n",
    "with open(\"basic_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "model.save_weights(\"basic_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
