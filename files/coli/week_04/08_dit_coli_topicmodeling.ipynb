{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, I will import the dependencies\n",
    "# the first time they are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thought Exercise\n",
    "\n",
    "Training a topic model with _common sense_\n",
    "\n",
    "1. Produce a random tf-idf representation of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "topic = {}\n",
    "# Function zip() returns an iterator of tuples, where the i-th tuple \n",
    "# contains the i-th element from each of the argument sequences\n",
    "\n",
    "# np.random.rand(i) produces an array of i random numbers\n",
    "\n",
    "tfidf = dict(list(zip('cat dog apple lion NYC love'.split(),\\\n",
    "                      np.random.rand(6))))\n",
    "# Random tf-idf vector for our single document\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Manually__ create common-sense weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we multiply the tf-idf vector by the \n",
    "# \"hand-crafted” weights (notice the subtractions)\n",
    "topic['petness'] = (\n",
    "                  .3 * tfidf['cat'] \n",
    "                + .3 * tfidf['dog'] \n",
    "                +  0 * tfidf['apple'] \n",
    "                +  0 * tfidf['lion'] \n",
    "                - .2 * tfidf['NYC'] \n",
    "                + .2 * tfidf['love'])\n",
    "topic['animalness'] = (\n",
    "                  .1 * tfidf['cat'] \n",
    "                + .1 * tfidf['dog'] \n",
    "                - .1 * tfidf['apple'] \n",
    "                + .5 * tfidf['lion'] \n",
    "                + .1 * tfidf['NYC'] \n",
    "                - .1 * tfidf['love'])\n",
    "topic['cityness'] = ( \n",
    "                   0 * tfidf['cat'] \n",
    "                - .1 * tfidf['dog'] \n",
    "                + .2 * tfidf['apple'] \n",
    "                - .1 * tfidf['lion'] \n",
    "                + .5 * tfidf['NYC'] \n",
    "                + .1 * tfidf['love'])\n",
    "topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Transposing the 6x3 matrix to produce **topic weights for each word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = {}\n",
    "\n",
    "word_vector['cat'] = [.3*topic['petness'],\n",
    "                    .1*topic['animalness'],\n",
    "                    0*topic['cityness']]\n",
    "\n",
    "word_vector['dog'] = [.3*topic['petness'],\n",
    "                    .1*topic['animalness'], \n",
    "                    -.1*topic['cityness']]\n",
    "\n",
    "word_vector['apple']= [0*topic['petness'],\n",
    "                    .1*topic['animalness'],\n",
    "                    .2*topic['cityness']]\n",
    "\n",
    "word_vector['lion'] = [0*topic['petness'],\n",
    "                    .5*topic['animalness'],\n",
    "                    -.1*topic['cityness']]\n",
    "word_vector['NYC'] = [-.2*topic['petness'],\n",
    "                    .1*topic['animalness'],\n",
    "                    .5*topic['cityness']]\n",
    "word_vector['love'] = [.2*topic['petness'],\n",
    "                    -.1*topic['animalness'],\n",
    "                    .1*topic['cityness']]\n",
    "word_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Linear Discriminant Analysis classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nlpia.data.loaders import get_data\n",
    "\n",
    "# Loading a labeled corpus: spam\n",
    "sms = get_data('sms-spam')\n",
    "print(sms[:-10])\n",
    "\n",
    "# Just setting up the printing properties\n",
    "pd.options.display.width = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For display purposes: spam instances have a \"!\" added to the label\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in \\\n",
    "         zip(range(len(sms)), sms.spam)]\n",
    "print(index[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'!'*0\n",
    "#'!'*1\n",
    "#'!'*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pandas df, using the data and the new index\n",
    "sms = pd.DataFrame(sms.values, columns=sms.columns, index=index)\n",
    "sms['spam'] = sms.spam.astype(int)\n",
    "print(sms)\n",
    "# len(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: what am I getting with this sum?\n",
    "sms.spam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorising the corpus\n",
    "tfidf_model = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf_model.fit_transform(raw_documents=sms.text).toarray()\n",
    "# QUESTION: what is the number on the right?\n",
    "print(tfidf_docs.shape)\n",
    "print(tfidf_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "We have \n",
    "* 4837 messages\n",
    "* 638 positive instances\n",
    "* 9232 types\n",
    "\n",
    "That's way too much for a Naïve Bayes' classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the LDA\n",
    "\n",
    "We just need the centroids of spam and non-spam, so we implement it \n",
    "\n",
    "(keep in mind that sklearn has an [LDA](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mask (or \"filter\") to select only spam messages\n",
    "mask = sms.spam.astype(bool).values\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the spam centroid\n",
    "spam_centroid = tfidf_docs[mask].mean(axis=0)\n",
    "# axis=0 tells numpy to compute the mean for each column independently\n",
    "print(spam_centroid.round(2))\n",
    "len(spam_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the ham centroid\n",
    "ham_centroid = tfidf_docs[~mask].mean(axis=0)\n",
    "print(ham_centroid.round(2))\n",
    "len(ham_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_centroid - ham_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the centroid difference: \"the line between spam and ham\"\n",
    "spamminess_score = tfidf_docs.dot(spam_centroid - ham_centroid)\n",
    "print(spamminess_score.round(2))\n",
    "len(spamminess_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not just subtracting. We computed the dot product!\n",
    "\n",
    "**spamminess_score** is $dis(centroid_{(spam)}, centroid_{(ham)})$\n",
    "\n",
    "We compute it by projecting each TF-IDF vector onto that line between the centroids using the dot product (those were indeed 4,837 dot products computed at once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the vector spamminess_score into matrix: \n",
    "spamminess_score.reshape(-1,1)\n",
    "# Because the input to the next function must have shape: (n_samples, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MinMaxScaler's fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.fit_transform) will scale each of the features to range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Turning the scores into \"probabilities\" \n",
    "sms['lda_score'] = MinMaxScaler().fit_transform(spamminess_score.reshape(-1,1))\n",
    "\n",
    "# Turning them into predictions\n",
    "sms['lda_predict'] = (sms.lda_score > .5).astype(int)\n",
    "\n",
    "# Displaying them\n",
    "sms['spam lda_predict lda_score'.split()].round(2).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the accuracy of the model?\n",
    "(1. - (sms.spam - sms.lda_predict).abs().sum() / len(sms)).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a confusion matrix\n",
    "from pugnlp.stats import Confusion\n",
    "\n",
    "Confusion(sms['spam lda_predict'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some pre-computed topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic vectors\n",
    "from nlpia.book.examples.ch04_catdog_lsa_3x6x16 import word_topic_vectors\n",
    "word_topic_vectors.T.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top0 $\\approx$ cityness. It contains the highest values for **apple** and **nyc**. It is the first in the LSA ordering. It has the **highest variance** in the dataset\n",
    "\n",
    "top1 $\\approx$ seems to be the one for **love** (see the last column)\n",
    "\n",
    "top2 $\\approx$ has a lot of **dog** and some **love**\n",
    "\n",
    "Not too much **love** for **cats** (but they are \"anti-city\")\n",
    "\n",
    "(the code to end up with this space is available from the book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
