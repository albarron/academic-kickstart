{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let us acquire a fresh corpus. \n",
    "\n",
    "As for many other datasets, NLTK includes an easy way to load a [Project Gutenberg](https://www.gutenberg.org/) corpus.\n",
    "\n",
    "See further information [here](https://www.nltk.org/book/ch02.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/albarron/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run only the first time\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [Project Gutenberg](https://www.gutenberg.org) if you want more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 375542; vocabulary size: 50\n",
      "\n",
      "[the tragedie of julius caesar by william shakespeare 1599]\n",
      "\n",
      "\n",
      "actus primus. scoena prima.\n",
      "\n",
      "enter flauius, murellus, and certaine commoners ouer the stage.\n",
      "\n",
      "  flauius. hence: home you idle creatures, get you home:\n",
      "is this a holiday? what, know you not\n",
      "(being mechanicall) you ought not walke\n",
      "vpon a labouring day, without the signe\n",
      "of your profession? speake, what trade art thou?\n",
      "  car. why sir, a carpenter\n",
      "\n",
      "   mur. where is thy leather apron, and thy rule?\n",
      "what dost thou with thy best apparrell on\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "for txt in gutenberg.fileids():\n",
    "    if 'shakespeare' in txt:\n",
    "        text += gutenberg.raw(txt).lower()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# dictionary from character to index | char -> one-hot\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# distionary from index to character | one-hot -> char\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# char -> one-hot\n",
    "# one-hot -> char\n",
    "# why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 375542; vocabulary size: 50\n",
      "\n",
      "[the tragedie of julius caesar by william shakespeare 1599]\n",
      "\n",
      "\n",
      "actus primus. scoena prima.\n",
      "\n",
      "enter flauius, murellus, and certaine commoners ouer the stage.\n",
      "\n",
      "  flauius. hence: home you idle creatures, get you home:\n",
      "is this a holiday? what, know you not\n",
      "(being mechanicall) you ought not walke\n",
      "vpon a labouring day, without the signe\n",
      "of your profession? speake, what trade art thou?\n",
      "  car. why sir, a carpenter\n",
      "\n",
      "   mur. where is thy leather apron, and thy rule?\n",
      "what dost thou with thy best apparrell on\n"
     ]
    }
   ],
   "source": [
    "print('corpus length: {}; vocabulary size: {}\\n'.format(len(text), len(chars)))\n",
    "# print(chars)\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective.** Predicting the 41st character after having seen 40 characters\n",
    "\n",
    "**Trick.** Adding redundancy to the training collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 125168 \n",
      "\n",
      "[the tragedie of julius caesar by willia -> m\n",
      "e tragedie of julius caesar by william s -> h\n",
      "ragedie of julius caesar by william shak -> e\n",
      "edie of julius caesar by william shakesp -> e\n",
      "e of julius caesar by william shakespear -> e\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "# Notice: no tokenisation; no sentence splitting; no linebreak elimination\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences), \"\\n\")\n",
    "print(\"\\n\".join(\n",
    "    [x + \" -> \" + y for x, y in zip(sentences[:5], next_chars[:5])]\n",
    "    ))\n",
    "# print(\"\\n\".join(sentences[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing the one-hot encoding (both input and output)\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 98,098\n",
      "Trainable params: 98,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "\n",
    "model = Sequential()\n",
    "# no return sequence. We just want the last output\n",
    "model.add(LSTM(128,\n",
    "    input_shape=(maxlen, len(chars))))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# why do we have a softmax and not a sigmoid?\n",
    "\n",
    "# https://keras.io/api/optimizers/rmsprop/; lr=learning rate (default: 0.001)\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "\n",
    "# no more binary cross entropy; no dropout. Why?\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical cross entropy**: diff between the probability distribution and the one-hot vector\n",
    "\n",
    "**No dropout**: Long live to overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "978/978 [==============================] - 65s 65ms/step - loss: 2.3718\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 67s 68ms/step - loss: 1.7223\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 67s 68ms/step - loss: 1.5891\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.5159\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.4556\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 76s 78ms/step - loss: 1.4146\n",
      "Epoch 1/6\n",
      "978/978 [==============================] - 75s 76ms/step - loss: 1.4129\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 69s 70ms/step - loss: 1.3920\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 68s 69ms/step - loss: 1.3735\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 68s 69ms/step - loss: 1.3598\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.3465\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.3363\n",
      "Epoch 1/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.3248\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 66s 68ms/step - loss: 1.3158\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 66s 68ms/step - loss: 1.3092\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 66s 67ms/step - loss: 1.3032\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 67s 68ms/step - loss: 1.2958\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 66s 68ms/step - loss: 1.2901\n",
      "Epoch 1/6\n",
      "978/978 [==============================] - 67s 68ms/step - loss: 1.2835\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 71s 73ms/step - loss: 1.2784\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 69s 70ms/step - loss: 1.2721\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 69s 70ms/step - loss: 1.2676\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.2646\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 67s 68ms/step - loss: 1.2587\n",
      "Epoch 1/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.2576\n",
      "Epoch 2/6\n",
      "978/978 [==============================] - 67s 69ms/step - loss: 1.2546\n",
      "Epoch 3/6\n",
      "978/978 [==============================] - 66s 67ms/step - loss: 1.2485\n",
      "Epoch 4/6\n",
      "978/978 [==============================] - 70s 71ms/step - loss: 1.2431\n",
      "Epoch 5/6\n",
      "978/978 [==============================] - 68s 70ms/step - loss: 1.2414\n",
      "Epoch 6/6\n",
      "978/978 [==============================] - 69s 70ms/step - loss: 1.2372\n"
     ]
    }
   ],
   "source": [
    "# Saving the architecture \n",
    "model_structure = model.to_json()\n",
    "with open(\"shakes_lstm_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "# Training \n",
    "epochs = 6\n",
    "batch_size = 128\n",
    "\n",
    "for i in range(5):\n",
    "#     print(\"i=\", i)\n",
    "    model.fit(X, y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    model.save_weights(\"shakes_lstm_weights_{}.h5\".format(i+1))\n",
    "    \n",
    "# Notice that we are *not* training for 6 epochs only (stop it whenever sounds alright; ~25 epochs)\n",
    "\n",
    "# Why am I not getting accuracies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temperature**\n",
    "\n",
    "temperature > 1 : more diverse outcome\n",
    "\n",
    "temperature < 1 : more strict (try to \"copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Sampler to generate character sequences\n",
    "    \n",
    "    temperature > 1 --> flattening the distribution\n",
    "    temperature < 1 --> sharpening the distribution\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    # produces a number of random outcomes, \n",
    "    # given a probability distribution\n",
    "    # n=1    number of experiments\n",
    "    # preds  probability distribution\n",
    "    # size=1 \n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.05\n",
      "----- Generating with seed: \"the day,\n",
      "thou canst not then be false to\"\n",
      "the day,\n",
      "thou canst not then be false to the stronke,\n",
      "and the strong to the strong to the strong to the strong to the great the strong to the gods\n",
      "\n",
      "   macb. there is no man and thates to the stronke,\n",
      "and the strong to the commiff's to the commiff's\n",
      "with the common the commiffes of the commiffes of the commiffes of the commiffes of the gare,\n",
      "and the selfe of the selfe of the commiffes of the gare,\n",
      "and the selfe of the strong to the stron\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the day,\n",
      "thou canst not then be false to\"\n",
      "the day,\n",
      "thou canst not then be false to the stronke,\n",
      "when i haue seene the capters that the banius,\n",
      "and the man thane of the seuerall constance\n",
      "\n",
      "   cassi. i will be best the time is this strange,\n",
      "and that the earth of the secose: if i am i haue the proudlesse to be strunch and vnsoule,\n",
      "and will heare of my selfe and that of the gods\n",
      "with the world strange to do heare the common the confirme,\n",
      "and the selfe of the selfe of the commiffes \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the day,\n",
      "thou canst not then be false to\"\n",
      "the day,\n",
      "thou canst not then be false to heauenly.\n",
      "but had the thing on the sir\n",
      "\n",
      "   macb. there is the right in his courtier of thy constancke,\n",
      "which will my lord, the after the some thankes,\n",
      "cryets with the violument of the command,\n",
      "as the soueraide of the strong with them.\n",
      "im some take a great it in the courtry, and better the dankes of his way,\n",
      "and man and briefe of the father, let vs heare them moue\n",
      "\n",
      "   ham. hamlet i will not be rec\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the day,\n",
      "thou canst not then be false to\"\n",
      "the day,\n",
      "thou canst not then be false to which is strange,\n",
      "to kinde on the earth inde vang fire your selfe,\n",
      "least will, yet proue you lands\n",
      "of atreckmes take straight: like a bann'd\n",
      "of talkes part of brutus; go font\n",
      "that that away as fightly, and come abouiely\n",
      "whe com se reader good inch allpher but it\n",
      "ious it rountie newes, all, i one well,\n",
      "and first come met by his offers. but vnderstand the stune,\n",
      "and sowit froffiction ioy, then know\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"the day,\n",
      "thou canst not then be false to\"\n",
      "the day,\n",
      "thou canst not then be false to command though leass,\n",
      "yetc'ly iumalet enemiers of aint octouie\n",
      "'ixt do good, tegh sir\n",
      "\n",
      "   macb. i'tch my enter't brothers no furrers: you,\n",
      "weak my ioyni\n",
      "\n",
      "   clet. i would, if to confresie thee, hath smile the king?\n",
      "  eleninis. i hayst are heaur rather hanne\n",
      "droph her yetch humbly and boundesse amissage.,\n",
      "she gothe heere bad plaw, and laerted, heere's\n",
      "our will whole know shio' of a mighty from em?\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "for diversity in [0.05, 0.2, 0.5, 1.0, 1.2]:\n",
    "    print()\n",
    "    print('----- diversity:', diversity)\n",
    "    # Getting a random starting text\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    for i in range(400):\n",
    "        # one-hot representation\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        # Producing the prediction\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        \n",
    "        # looking up the next character and adding it \n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        \n",
    "        #updating the seed\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()  # to display it right away\n",
    "    print()\n",
    "    \n",
    "# lower values should look \"more Shakesperean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
