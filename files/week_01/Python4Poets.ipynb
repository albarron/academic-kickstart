{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Poets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is inspired on Keneth W. Church's [Unix for Poets](https://www.cs.upc.edu/~padro/Unixforpoets.pdf). From that chapter itself:\n",
    "\n",
    "- \"many researchers have more data than they know what to do with\"\n",
    "- \"Many researchers believe that they don’t have sufficient computing resources to do these things for themselves.\"\n",
    "- \"This chapter will describe a set of simple Unix-based (**Python in our case**) tools that should\n",
    "be more than adequate for counting trigrams on a corpus the size of the Brown Corpus\"\n",
    "- \"this chapter will focus on examples and avoid definitions whenever possible\"\n",
    "\n",
    "The code has been developed using Python 3.6. It has been written using [PyCharm](), and tested on [Colab](). All snippets could be run in any machine with Python 3.6 (or higher) installed, or online, as a Jupyter notebook.\n",
    "\n",
    "Note that many of these exercises would be indeed simpler using simple one-liners on the Unix/Linux command line!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Excercise 1: Count words in a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Chuch. \"The problem is to input a text file, say Genesis (a good place to start),2 and output a list of words in the file along with their frequency counts. The algorithm consists of three steps:\"\n",
    "\n",
    "1. Tokenize the text into a sequence of words (_re_),\n",
    "2. Count the words (with a _dictionary_ or with _Counter_)\n",
    "\n",
    "The algorithm can be implemented in just three lines of Unix code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eor7NbtKDVs0"
   },
   "outputs": [],
   "source": [
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    txt = input.read()\n",
    "\n",
    "# Apply a regular expression to the string txt and look for all occurrences of the given pattern\n",
    "tokens = re.findall('[A-Za-z]+', txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eor7NbtKDVs0"
   },
   "outputs": [],
   "source": [
    "# Option 1: using a dictionary\n",
    "d = {}\n",
    "for tok in tokens:\n",
    "    if tok not in d:\n",
    "        d[tok] = 0\n",
    "    d[tok] += 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: using a counter\n",
    "from collections import Counter\n",
    "c = Counter(tokens)\n",
    "print(c)\n",
    "\n",
    "print(c['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A comment in Python starts with #. The compiler/interpreter does not execute anything coming after a #.\n",
    "- There are many official Python (and contributed) libraries available. They are imported with _import_\n",
    "- Once a library is imported, we have access to all its methods and classes \n",
    "- The contents of a (text) file are accessed with _open()_\n",
    "- Regular expressions are powerful tools to find patterns\n",
    "- Lists are precisely that: lists of elements. \n",
    "- Dictionaries are key-value pairs\n",
    "- Loops are repetitions until certain condition is true (here we use _for_)\n",
    "- Conditionals execute a code if a condition is true (here we use a simple _if_)\n",
    "- We can display the contents of a variable with _print()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 20 words in the text\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the words in the list\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count again, this time on the sorted_tokens\n",
    "\n",
    "d = {}\n",
    "for tok in sorted_tokens:\n",
    "    if tok not in d:\n",
    "        d[tok] = 0\n",
    "    d[tok] += 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sort a list of words in various ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the case when counting: lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = None\n",
    "tokens = re.findall('[A-Za-z]+', txt)\n",
    "tokens = sorted(tokens)\n",
    "\n",
    "c = Counter(tokens)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count sequences of vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = re.findall('[aeiou]+', txt)\n",
    "c = Counter(vowels)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count sequences of consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants = re.findall('[bcdfghjklmnpqrstvwxyz]+', txt)\n",
    "c = Counter(consonants)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Unix for poets**\n",
    "\n",
    "\"These three examples are intended to show how easy it is to change the definition of what counts as a word. Sometimes you want to distinguish between upper and lower case, and sometimes you don’t [...] The same basic counting program can be used to count a variety of different things, depending on how you implement the definition of thing (=token).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKtW0ep_Dl6f"
   },
   "source": [
    "### 2.1 Sort in dictionary order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    txt = input.read()\n",
    "\n",
    "# Apply a regular expression to the string txt and look for all occurrences of the given pattern\n",
    "tokens = re.findall('[A-Za-z]+', txt)\n",
    "\n",
    "sorted_tokens = sorted(tokens)\n",
    "print(sorted_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sort in \"rhyming\" order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this method!\n",
    "def invert(word):\n",
    "    return word[::-1]\n",
    "\n",
    "# Note the additional parameter\n",
    "rythm_tokens = sorted(tokens, key=invert)\n",
    "\n",
    "print(rythm_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAIATCL_DrxQ"
   },
   "source": [
    "## 3. Compute n-gram statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = None \n",
    "c = Counter(bigrams)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = [\" \".join(tokens[i:i+3]) for i in range(len(tokens)-2)]\n",
    "c = Counter(trigrams)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **any** n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "grams = [\" \".join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "c = Counter(grams)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, **from Unix for poets**\n",
    "\n",
    "Suppose that you found that you were often computing trigrams of different things, and you found it\n",
    "inconvenient to keep typing the same five lines over and over. If you put the following **method**, then you could count n-grams with one single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens, n):\n",
    "    return [\" \".join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "four_grams = ngrams(tokens, 4)\n",
    "c = Counter(four_grams)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Counting n-grams from verses containing the phrase \"the land of\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent 3-gram is \"the land of\". Let us count the 3-grams in verses containing \"the land of\" only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    txt = \" \".join([x for x in input.readlines() if \"the land of\" not in x]) \n",
    "tokens = re.findall('[A-Za-z]+', txt)\n",
    "three_grams = ngrams(tokens, 3)\n",
    "c = Counter(three_grams)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us count the 3-grams in verses **not** containing \"the land of\" only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    txt = None \n",
    "tokens = re.findall('[A-Za-z]+', txt)\n",
    "three_grams = ngrams(tokens, 3)\n",
    "c = Counter(three_grams)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Ignore lines containing \"gh\"\n",
    "2. Consider only lines ending with \"ing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take-home exercises\n",
    "1. How many uppercase tokens are in this version of Genesis?\n",
    "2. How many 4-letter words?\n",
    "3. Are there words without vowels?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Get the _k_ most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    txt = \" \".join([x for x in input.readlines() if \"the land of\" in x])\n",
    "tokens = re.findall('[A-Za-z]+', txt)\n",
    "three_grams = ngrams(tokens, 1)\n",
    "c = Counter(three_grams)\n",
    "c.most_common(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all n-grams appearing only **k times**. An then let's try to find out the longest n-grams appearing at least 5 times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "k = 5\n",
    "\n",
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    txt = input.read()\n",
    "\n",
    "# Apply a regular expression to the string txt and look for all occurrences of the given pattern\n",
    "tokens = re.findall('[A-Za-z]+', txt)\n",
    "# NOTE THIS HORRIBLE THING I DID HERE!!!\n",
    "ngrams = ngrams(tokens, n)\n",
    "\n",
    "c = Counter(ngrams)\n",
    "my_ngrams = None\n",
    "print(my_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find palyndroms in Genesis\n",
    "\n",
    "We will use the comparator **==** to find out whether a statement is true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palyndromes = []\n",
    "None \n",
    "c = Counter(palyndromes)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "(from Church)\n",
    "1. It is said that English avoids sequences of _-ing_ words. Find bigrams where both words end in _-ing_. Do these count as counter-exampes of the _-ing -ing_ rule?\n",
    "2. For comparison's sake, find bigrams where bth words end in _-ed_. Should there also be a prohibition against _-ed -ed_? Are there anu examples of _-ed -ed_ in Genesis? If so, how many? Which verse(s)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1. Using a regular expression over the already computed n-grams\n",
    "\n",
    "grams = ngrams(tokens, 2)\n",
    "regexp = re.compile('.+ing .+ing$')\n",
    "ing_ing = [x for x in grams if regexp.match(x)]\n",
    "print(ing_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2. Using string operations\n",
    "grams = ngrams(tokens, 2)\n",
    "ing_ing = []\n",
    "for gram in grams:\n",
    "    pair = gram.split(\" \")\n",
    "    if pair[0].endswith(\"ing\") and pair[1].endswith(\"ing\"):\n",
    "        ing_ing.append(gram)\n",
    "print(ing_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it for \"-ed -ed\" here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Print out verses containing the phrase \"Let there be light\". Print out the previous verse as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = \"Let there be light\"\n",
    "\n",
    "with open(\"genesis.txt\", 'r') as input:\n",
    "    verses = input.readlines()\n",
    "    \n",
    "for verse in verses:\n",
    "    if my_str in verse:\n",
    "        print(verse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the two verses. **How can we print the previous verse as well???**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the previous code snippet to print the previous sentence as well\n",
    "None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. String substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_lines(file, k=10):\n",
    "    with open(file) as f:\n",
    "        head = [next(f) for x in range(k)]\n",
    "    return head\n",
    "\n",
    "txt = top_k_lines(\"genesis.txt\")\n",
    "# print(txt)\n",
    "for line in txt:\n",
    "    print(line.replace(\"God\", \"The Spaghetti Monster\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mutual information to find collocations\n",
    "\n",
    "From the Wikipedia articles on [mutual information](https://en.wikipedia.org/wiki/Mutual_information#Applications_2) and [collocations](https://en.wikipedia.org/wiki/Collocation)\n",
    "\n",
    "In probability theory and information theory, the mutual information (MI) of two random variables is a measure of the **mutual dependence between the two variables**. More specifically, it quantifies the \"amount of information\" (in units such as shannons, commonly called bits) obtained about one random variable through observing the other random variable.\n",
    "\n",
    "Mutual information of words is often used as a **significance function for the computation of collocations in corpus**\n",
    "\n",
    "A collocation is a series of words or terms that co-occur **more often than would be expected by chance**.\n",
    "Mutiual information is defined as\n",
    "\n",
    "$MI(x,y) = log_2 \\frac{Pr(x,y)}{Pr(x) Pr(y)}$\n",
    "\n",
    "and, following [Magerman and Marcus](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.4178&rep=rep1&type=pdf), in NLP it can be estimated as \n",
    "\n",
    "$MI(x,y) \\approx log \\frac{\\frac{f(x,y)}{\\sum_{(i,j)\\in C}f(i,j)}}{\\frac{f(x)}{\\sum_{i\\in C}{f(x)}} \\frac{f{y}}{\\sum_{i\\in C}f(y)} }$\n",
    "\n",
    "where $\\sum_{\\cdot}$ is the sum over all instances of $\\cdot$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Chuch. \"The problem is to input a text file, say Genesis (a good place to start),2 and output a list of words in the file along with their frequency counts. The algorithm consists of three steps:\"\n",
    "\n",
    "1. Tokenize the text into a sequence of words (_re_),\n",
    "2. Count the words (with a _dictionary_ or with _Counter_)\n",
    "\n",
    "The algorithm can be implemented in just three lines of Unix code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "bigrams = ngrams(tokens, 2)\n",
    "unigrams = ngrams(tokens, 1)\n",
    "\n",
    "freq_bigrams = Counter(bigrams)\n",
    "freq_unigrams = Counter(unigrams)\n",
    "\n",
    "sum_bigrams = sum(freq_bigrams.values())\n",
    "sum_unigrams = sum(freq_unigrams.values())\n",
    "\n",
    "print(sum_bigrams, sum_unigrams)\n",
    "#freqs_x_y = grams = \n",
    "\n",
    "my_str = [\"God\", \"created\"]\n",
    "my_str = [\"of\", \"Esau\"]\n",
    "my_str = [\"LORD\", \"said\"]\n",
    "\n",
    "mi = log((freq_bigrams[\" \".join(my_str)] / sum_bigrams) / \n",
    "          ( (freq_unigrams[my_str[0]] / sum_unigrams) * (freq_unigrams[my_str[1]] / sum_unigrams)  )  )\n",
    "\n",
    "print(\"mi(%s, %s) = %f\" % (my_str[0], my_str[1], mi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but these are just MLE probabilities!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "bigrams = ngrams(tokens, 2)\n",
    "unigrams = ngrams(tokens, 1)\n",
    "\n",
    "freq_bigrams = Counter(bigrams)\n",
    "freq_unigrams = Counter(unigrams)\n",
    "\n",
    "sum_bigrams = sum(freq_bigrams.values())\n",
    "sum_unigrams = sum(freq_unigrams.values())\n",
    "\n",
    "print(sum_bigrams, sum_unigrams)\n",
    "\n",
    "for k in freq_bigrams:\n",
    "    freq_bigrams[k] /= sum_bigrams\n",
    "    \n",
    "for k in freq_unigrams:\n",
    "    freq_unigrams[k] /= sum_unigrams\n",
    "\n",
    "#freqs_x_y = grams = \n",
    "\n",
    "my_str = [\"God\", \"created\"]\n",
    "my_str = [\"of\", \"Esau\"]\n",
    "my_str = [\"LORD\", \"said\"]\n",
    "\n",
    "mi = log((freq_bigrams[\" \".join(my_str)]) / \n",
    "          ( (freq_unigrams[my_str[0]]) * (freq_unigrams[my_str[1]])  )  )\n",
    "\n",
    "print(\"mi(%s, %s) = %f\" % (my_str[0], my_str[1], mi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises (once again, from Church)\n",
    "\n",
    "1. Compute the $MI(x,y) \\forall (x,y) \\in C$ (Compute $MI(x,y)$ for all pair in the corpus\n",
    "2. MI is unestable for small bigram counts. Compute (or display) MI only for those bigrams x such that $f(x)\\geq 5$.\n",
    "3. Find the 10 bigrams in Genesis with the largest MI.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Python4Poets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
