{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Naive Bayes Classifier\n",
    "\n",
    "Now we will use annotated data to \"learn\" a sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dependencies\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nlpia.data.loaders import get_data \n",
    "\n",
    "# The casual tokenizer can handle emoticons, unusual punctuation and slang better than the TreeBank tokenizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the \"corpus\"\n",
    "\n",
    "Loading the movies corpus from Hutto movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = get_data('hutto_movies')\n",
    "\n",
    "# Looking at some of the first instances\n",
    "movies.head().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a description of the data (look at the range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helps display wide DataFrames in the console, so they look prettier\n",
    "pd.set_option('display.width', 75)\n",
    "movies.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data into a DataFrame through a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_of_words = []\n",
    "\n",
    "for text in movies.text:\n",
    "    bags_of_words.append(Counter(casual_tokenize(text)))\n",
    "\n",
    "df_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "\n",
    "# from_records() is a DataFrame constructor.\n",
    "# INPUT: a sequence (list) of dictionaries\n",
    "# OUTPUT: a DF with columns for all the keys and associated values. Missing values become NaN\n",
    "print(df_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we fill them with 0:\n",
    "df_bows = df_bows.fillna(0).astype(int)\n",
    "print(df_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us look at the shape\n",
    "\n",
    "Spoiler: A BoW can explode in size; even more when no normalisation is applied at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bows.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see the top instances (it is quite sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bows.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Homework**: Integrate the normalisation pipeline to see the difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bows.head()[list(bags_of_words[0].keys())])\n",
    "\n",
    "#print(df_bows.head()[list(bags_of_words[1].keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Naive Bayes classifier\n",
    "\n",
    "All the data is now ready. Let us build a Multinomial NB.\n",
    "\n",
    "Multimodal NB is suitable for discrete features (e.g., word counts for text classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.sentiment > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train (\"fit\") our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are converting the class from float to Boolean, \n",
    "# as this classifier only supports discrete labels \n",
    "nb = nb.fit(df_bows, movies.sentiment > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a model and we can predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba() gets continious-value predictions.\n",
    "# We multiply and subtract it to convert the output to range [-4,4]\n",
    "\n",
    "#print(predictions[:10])\n",
    "# TODO there seems to be an error in th ebook code. \n",
    "# predict_proba returns the scores for all the classes (2) and we aim at\n",
    "# assigning only the one for the positive class. \n",
    "# I had to to the following trick instead of the original\n",
    "# movies['predicted_sentiment'] = nb.predict(df_bows) * 8 - 4\n",
    "predictions = nb.predict_proba(df_bows) * 8 - 4 \n",
    "movies['predicted_sentiment'] = [x[1] for x in predictions]\n",
    "\n",
    "# FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-4,4]\n",
    "\n",
    "probability [0,1]\n",
    "\n",
    "0* 8 -> 0\n",
    "1 * 8 -> 8\n",
    "\n",
    "[0,8] -4 -> [-4,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute the Mean Absolut Error (MAE) \"a measure of difference between two continuous variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs()\n",
    "# This is the mean absolute error (MAE)\n",
    "movies.error.mean().round(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see some gold and predicted sentiments, together with the binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold standard is positive\n",
    "movies['sentiment_ispositive'] = (movies.sentiment > 0).astype(int)\n",
    "\n",
    "# Prediction is positive\n",
    "movies['predicted_ispositive'] = (movies.predicted_sentiment > 0).astype(int)\n",
    "\n",
    "# Let us have an overview of gold standard vs prediction\n",
    "movies['''sentiment predicted_sentiment sentiment_ispositive predicted_ispositive'''.split()].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is the percentage of \"thumbs up\" rating correctly predicted    \n",
    "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
